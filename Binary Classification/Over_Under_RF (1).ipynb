{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f1c599-f0c7-46b2-8b05-fb044284a59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4615d873-3f90-4b5c-8dbe-7ef87c9bee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('understat_per_game.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03892fc8-8e60-4af2-b73a-164bb9314162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removing outliers: (24420, 29)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Handle outliers in the target variable ('scored') using the IQR method\n",
    "Q1 = data['scored'].quantile(0.25)\n",
    "Q3 = data['scored'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "data = data[(data['scored'] >= lower_bound) & (data['scored'] <= upper_bound)]\n",
    "print(f\"Dataset shape after removing outliers: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fa2bb0-d852-41a2-8a89-1c3457bf45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create target classes for binary classification (under 2.5 goals = 0, over 2.5 goals = 1)\n",
    "def classify_binary_goals(goals):\n",
    "    return 1 if goals > 2.5 else 0\n",
    "\n",
    "data['scored_binary'] = data['scored'].apply(classify_binary_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088172e-7687-4bce-a3ea-60a8520d539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Drop high-correlation features and non-useful columns\n",
    "high_corr_features = ['pts', 'npxG', 'npxGD', 'xG', 'xG_diff', 'wins', 'npxG', \n",
    "                      'xpts', 'xGA_diff', 'xGA', 'npxGA', 'xpts_diff', 'loses', 'draws']\n",
    "data = data.drop(columns=high_corr_features + ['result', 'date', 'team', 'scored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af513c3-7cee-4298-a456-beed9e08846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Feature Engineering\n",
    "data['ppda_efficiency'] = data['ppda_att'] / (data['ppda_def'] + 1)\n",
    "data['oppda_efficiency'] = data['oppda_att'] / (data['oppda_def'] + 1)\n",
    "data['relative_ppda_efficiency'] = data['ppda_efficiency'] / (data['oppda_efficiency'] + 1)\n",
    "data['ppda_intensity'] = data['ppda_coef'] * data['ppda_att']\n",
    "data['oppda_intensity'] = data['oppda_coef'] * data['oppda_att']\n",
    "data['intensity_diff'] = data['ppda_intensity'] - data['oppda_intensity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565771d-17ef-410b-b240-4666297a2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to categorical columns ('h_a', 'league')\n",
    "data = pd.get_dummies(data, columns=['h_a', 'league'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fb4cf-0a52-4209-b332-b19e32b9a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define target and features for binary classification\n",
    "X = data.drop(columns=['scored_binary'])  # Features\n",
    "y = data['scored_binary']  # Target variable (binary classes)\n",
    "\n",
    "# Step 7: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Initialize Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"  # Handle class imbalance\n",
    ")\n",
    "\n",
    "# Step 9: Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 10: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 11: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Under 2.5', 'Over 2.5'], yticklabels=['Under 2.5', 'Over 2.5'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (Binary Classification - Random Forest)')\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Cross-Validation Accuracy\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"\\nCross-Validation Accuracy:\")\n",
    "print(f\"Mean: {cv_scores.mean():.4f}, Std: {cv_scores.std():.4f}\")\n",
    "print(f\"Scores: {cv_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c009d0-7777-448a-9f49-a7e10c90f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Feature Importance based on Random Forest:\")\n",
    "print(feature_importance.head(20))\n",
    "\n",
    "# Plot Feature Importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(20), x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Top 20 Feature Importances (Binary Classification - Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
